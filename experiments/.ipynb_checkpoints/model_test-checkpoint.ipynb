{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594635ab-9ad8-4d03-b695-b484c3a35062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43144f0-1963-40e0-bd23-8674993897a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch.nn.functional as F\n",
    "from utils import get_edge_index_and_theta\n",
    "from model import FuzzyDirGCN\n",
    "import torch\n",
    "\n",
    "import importlib\n",
    "import utils.data_loading\n",
    "\n",
    "# Reload the entire module\n",
    "importlib.reload(utils.data_loading)\n",
    "\n",
    "# Now, re-import the specific function\n",
    "from utils.data_loading import (\n",
    "    get_classification_dataset,\n",
    "    get_graph_ensemble_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e92df8f-d977-42e0-a515-4d354d9fdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set the seed for Python's built-in random module\n",
    "    # Set the seed for NumPy (if you're using it)\n",
    "    np.random.seed(seed)\n",
    "    # Set the seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    # If using a GPU, ensure that all operations are deterministic\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a1e7657-fba7-4b77-9f9a-8368204d5f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([328000, 1]) torch.float32\n",
      "torch.Size([992000, 1]) torch.float32\n",
      "epoch: 0, tr/val loss: 142.45038/59.41861/72.98656, # non-decreasing steps: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([328000, 1]) torch.float32\n",
      "torch.Size([992000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([328000, 1]) torch.float32\n",
      "torch.Size([992000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([328000, 1]) torch.float32\n",
      "torch.Size([992000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n",
      "torch.Size([32000, 1]) torch.float32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 518\u001b[0m\n\u001b[1;32m    514\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(param_groups)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 518\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_theta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m test(mp_type, model, val_loader, edge_weight, opt_theta)\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n",
      "Cell \u001b[0;32mIn[73], line 433\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(mp_type, model, optimizer, train_loader, edge_weight, theta)\u001b[0m\n\u001b[1;32m    431\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(batch\u001b[38;5;241m.\u001b[39mx, batch\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m    432\u001b[0m loss \u001b[38;5;241m=\u001b[39m masked_regression_loss(pred, batch\u001b[38;5;241m.\u001b[39my, batch\u001b[38;5;241m.\u001b[39mmask)\n\u001b[0;32m--> 433\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch\u001b[38;5;241m.\u001b[39mnum_graphs\n\u001b[1;32m    435\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Software/miniconda3/envs/torch2/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Software/miniconda3/envs/torch2/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iclr_edge = pickle.load(open('../../ICLR/experiments/experiments_for_perturb_seq/edge.pkl', 'rb'))\n",
    "data = pickle.load(open('../datasets/perturb_seq/Replogle-gwps.pkl', 'rb'))\n",
    "edge_index = torch.tensor(data['edge_index'], device=device)\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.nn import MessagePassing, JumpingKnowledge\n",
    "from torch_geometric.typing import OptTensor\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "\n",
    "class FuzzyDirGCNConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels, \n",
    "        out_channels, \n",
    "        bias=True, \n",
    "        aggr_method=\"add\", \n",
    "        self_loop=False,\n",
    "        dtype=torch.float,\n",
    "    ):\n",
    "        super(FuzzyDirGCNConv, self).__init__(aggr=aggr_method)\n",
    "        #super(self).__init__(aggr=aggr_method)\n",
    "        self.aggr = aggr_method \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.self_loop = self_loop    \n",
    "\n",
    "        # Define linear layers for source-to-destination and destination-to-source directions\n",
    "        self.lin_src_to_dst = Linear(in_channels, out_channels, \n",
    "            bias=False, weight_initializer='glorot')\n",
    "\n",
    "        #self.lin_src_to_dst = torch.nn.Linear(in_channels, out_channels,\n",
    "        #    bias=False, dtype=dtype)\n",
    "        self.lin_dst_to_src = Linear(in_channels, out_channels, bias=False, weight_initializer='glorot')\n",
    "        #self.lin_dst_to_src = torch.nn.Linear(in_channels, out_channels,\n",
    "        #                             bias=False, dtype=dtype)\n",
    "\n",
    "        if self.self_loop:\n",
    "            self.lin_self = Linear(in_channels, out_channels, bias=False, weight_initializer='glorot')\n",
    "            #self.lin_self = torch.nn.Linear(in_channels, out_channels,\n",
    "            #                       bias=False, dtype=dtype)\n",
    "        else:\n",
    "            self.lin_self = None\n",
    "\n",
    "        if bias:\n",
    "            self.bias_src_to_dst = Parameter(torch.empty(out_channels))\n",
    "            self.bias_dst_to_src = Parameter(torch.empty(out_channels))\n",
    "            # if dtype==torch.float:\n",
    "            #     self.bias_src_to_dst = torch.nn.Parameter(\n",
    "            #         self.bias_src_to_dst.to(torch.float32))\n",
    "            #     self.bias_dst_to_src = torch.nn.Parameter(\n",
    "            #         self.bias_dst_to_src.to(torch.float32))\n",
    "            # elif dtype==torch.double:\n",
    "            #     self.bias_src_to_dst = torch.nn.Parameter(\n",
    "            #         self.bias_src_to_dst.to(torch.float64))\n",
    "            #     self.bias_dst_to_src = torch.nn.Parameter(\n",
    "            #         self.bias_dst_to_src.to(torch.float64))          \n",
    "            if self.self_loop:\n",
    "                self.bias_self = Parameter(torch.empty(out_channels))\n",
    "                # if dtype==torch.float:\n",
    "                #     self.bias_self = torch.nn.Parameter(\n",
    "                #         self.bias_self.to(torch.float32))\n",
    "                # elif dtype==torch.double:\n",
    "                #     self.bias_self = torch.nn.Parameter(\n",
    "                #         self.bias_self.to(torch.float64))\n",
    "            else:\n",
    "                self.bias_self = None\n",
    "        else:\n",
    "            self.bias_src_to_dst = None\n",
    "            self.bias_dst_to_src = None\n",
    "            self.bias_self = None\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.lin_src_to_dst)\n",
    "        glorot(self.lin_dst_to_src)\n",
    "        zeros(self.bias_src_to_dst)\n",
    "        zeros(self.bias_dst_to_src)\n",
    "        if self.lin_self is not None:\n",
    "            glorot(self.lin_dst_to_src)\n",
    "        if self.bias_self is not None:\n",
    "            zeros(self.bias_self)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight) -> Tensor:\n",
    "        num_nodes = x.size(0)\n",
    "        #senders, receivers = edge_index\n",
    "        edge_weight_src_to_tgt, edge_weight_tgt_to_src = edge_weight\n",
    "\n",
    "        #print(x.shape, senders.shape, receivers.shape)\n",
    "\n",
    "        x_src_to_dst = self.propagate(edge_index, x=x, \n",
    "                                      edge_weight=edge_weight_src_to_tgt)\n",
    "        x_dst_to_src = self.propagate(edge_index, x=x, \n",
    "                                      edge_weight=edge_weight_tgt_to_src)\n",
    "\n",
    "        x_src_to_dst = self.lin_src_to_dst(x_src_to_dst)\n",
    "        x_dst_to_src = self.lin_dst_to_src(x_dst_to_src)\n",
    "\n",
    "        if self.bias_src_to_dst is not None:\n",
    "            x_src_to_dst = x_src_to_dst + self.bias_src_to_dst\n",
    "            x_dst_to_src = x_dst_to_src + self.bias_dst_to_src\n",
    "\n",
    "        if self.self_loop:\n",
    "            x_self = self.lin_self(x)\n",
    "            if self.bias_self is not None:\n",
    "                x_self = x_self + self.bias_self\n",
    "            return x_src_to_dst, x_dst_to_src, x_self\n",
    "        else:\n",
    "            return x_src_to_dst, x_dst_to_src\n",
    "\n",
    "    def message(self, x_j, edge_weight):\n",
    "        return x_j * edge_weight.view(-1, 1)\n",
    "\n",
    "\n",
    "class FuzzyDirGCNLayer(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, num_edges, mix_self_with_dir, in_channels, out_channels, bias=True, aggr_method='add', self_loop=False):     \n",
    "        super().__init__()\n",
    "        self.get_fuzzy_laplacian = lambda e, t, w: get_fuzzy_laplacian(\n",
    "            e, t, num_nodes, num_edges, w, mix_self_with_dir, 2)\n",
    "        self.conv = FuzzyDirGCNConv(in_channels, out_channels, bias=bias, self_loop=self_loop)\n",
    "        self.conv.reset_parameters()\n",
    "        \n",
    "    def forward(self, x, edge_index, theta, edge_weight=None):\n",
    "        conv_edge_index, conv_edge_weight = self.get_fuzzy_laplacian(\n",
    "            edge_index, theta, edge_weight) \n",
    "        xs = self.conv(x, conv_edge_index, conv_edge_weight)\n",
    "        #print(conv_edge_weight[0].sum(), conv_edge_weight[1].sum())\n",
    "\n",
    "        if len(xs) == 3:\n",
    "            x_src_to_dst, x_dst_to_src, x_self = xs\n",
    "            return 0.5 * x_src_to_dst + 0.5 * x_dst_to_src + x_self\n",
    "        elif len(xs) == 2:\n",
    "            x_src_to_dst, x_dst_to_src = xs\n",
    "            return x_src_to_dst + x_dst_to_src\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "\n",
    "\n",
    "def get_fuzzy_laplacian(\n",
    "    edge_index: torch.Tensor,\n",
    "    theta: torch.Tensor, \n",
    "    num_nodes: int,\n",
    "    num_edges: int,\n",
    "    edge_weight: Optional[torch.Tensor] = None,\n",
    "    add_self_loop: Optional[bool] = False,\n",
    "    power: Optional[int] = 2,\n",
    "):\n",
    "    \n",
    "    assert num_edges == theta.size(0)\n",
    "    if edge_weight is not None:\n",
    "        assert num_edges == edge_weight.size(0)\n",
    "\n",
    "    #edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "\n",
    "    if edge_weight is not None:\n",
    "        edge_weight = edge_weight\n",
    "    else:\n",
    "        edge_weight = torch.ones(edge_index.size(1), dtype=theta.dtype)\n",
    "        edge_weight.to(theta.device)\n",
    "\n",
    "    senders, receivers = edge_index[:, :num_edges]\n",
    "\n",
    "    edge_director_src_to_tgt = torch.exp(1j * theta)\n",
    "    edge_director_tgt_to_src = torch.exp(1j * (torch.pi / 2 - theta))\n",
    "    \n",
    "    conv_senders = torch.cat((senders, receivers))\n",
    "    conv_receivers = torch.cat((receivers, senders))\n",
    "    edge_director = torch.cat((edge_director_src_to_tgt, edge_director_tgt_to_src))\n",
    "    edge_weight = torch.cat((edge_weight, edge_weight))\n",
    "\n",
    "    if add_self_loop:\n",
    "        self_loops = torch.arange(num_nodes).to(conv_senders.device)\n",
    "        conv_senders = torch.cat((conv_senders, self_loops))\n",
    "        conv_receivers = torch.cat((conv_receivers, self_loops))\n",
    "        edge_weight = torch.cat((edge_weight, torch.ones(num_nodes).to(conv_senders.device)))\n",
    "        edge_director = torch.cat((edge_director, torch.full((num_nodes,), 1 + 1j).to(conv_senders.device)))\n",
    "\n",
    "    out_weight = edge_director.real**2 * edge_weight\n",
    "    in_weight = edge_director.imag**2 * edge_weight\n",
    "\n",
    "    # Graph is symmetric, so use conv_senders for both\n",
    "    #deg_senders = scatter_add(out_weight, conv_senders, dim=0, dim_size=num_nodes) + 1e-12\n",
    "    #deg_receivers = scatter_add(in_weight, conv_senders, dim=0, dim_size=num_nodes) + 1e-12\n",
    "    deg_senders = torch.zeros(num_nodes, dtype=out_weight.dtype, device=theta.device) + 1e-12\n",
    "\n",
    "    deg_senders.scatter_add_(0, conv_senders, out_weight) \n",
    "    deg_receivers = torch.zeros(num_nodes, dtype=out_weight.dtype, device=theta.device) + 1e-12\n",
    "    deg_receivers.scatter_add_(0, conv_senders, in_weight) \n",
    "\n",
    "    #deg_inv_sqrt_senders = torch.rsqrt(deg_senders)\n",
    "    #deg_inv_sqrt_senders.masked_fill_(deg_inv_sqrt_senders == float('inf'), 0.)\n",
    "    #deg_inv_sqrt_senders = torch.where(deg_senders<1e-11, 0.0, torch.rsqrt(deg_senders))\n",
    "    if power==2:\n",
    "        deg_inv_sqrt_senders = torch.where(deg_senders<1e-11, 0.0, torch.rsqrt(deg_senders))\n",
    "    elif power==4:\n",
    "        deg_inv_sqrt_senders = torch.where(deg_senders<1e-11, 0.0, 1 / deg_senders**4)\n",
    "    \n",
    "    #deg_inv_sqrt_receivers = torch.rsqrt(deg_receivers)\n",
    "    #deg_inv_sqrt_receivers.masked_fill_(deg_inv_sqrt_receivers == float('inf'), 0.)\n",
    "    if power==2:\n",
    "        deg_inv_sqrt_receivers = torch.where(deg_receivers<1e-11, 0.0, torch.rsqrt(deg_receivers))\n",
    "    elif power==4:\n",
    "        deg_inv_sqrt_receivers = torch.where(deg_receivers<1e-11, 0.0, 1 / deg_receivers**4)\n",
    "    \n",
    "    edge_weight_src_to_tgt = deg_inv_sqrt_senders[conv_senders] * out_weight * deg_inv_sqrt_receivers[conv_receivers]\n",
    "    edge_weight_tgt_to_src = deg_inv_sqrt_receivers[conv_senders] * in_weight * deg_inv_sqrt_senders[conv_receivers]   \n",
    "\n",
    "    num_repeat = edge_index.shape[1] // num_edges\n",
    "    conv_senders_batch, conv_receivers_batch = [conv_senders], [conv_receivers]\n",
    "    for n in range(1, num_repeat):\n",
    "        conv_senders_batch.append(num_nodes * n + conv_senders)\n",
    "        conv_receivers_batch.append(num_nodes * n + conv_receivers)\n",
    "    conv_senders_batch = torch.cat(conv_senders_batch)\n",
    "    conv_receivers_batch = torch.cat(conv_receivers_batch)\n",
    "\n",
    "    edge_weight_src_to_tgt_batch = edge_weight_src_to_tgt.repeat(num_repeat).unsqueeze(-1)\n",
    "    edge_weight_tgt_to_src_batch = edge_weight_tgt_to_src.repeat(num_repeat).unsqueeze(-1)\n",
    "    \n",
    "    # return (\n",
    "    #     torch.stack((conv_senders, conv_receivers), dim=0),\n",
    "    #     (edge_weight_src_to_tgt.unsqueeze(-1), edge_weight_tgt_to_src.unsqueeze(-1)),\n",
    "    # )\n",
    "    return (\n",
    "        torch.stack((conv_senders_batch, conv_receivers_batch), dim=0),\n",
    "        (edge_weight_src_to_tgt_batch, edge_weight_tgt_to_src_batch),\n",
    "    )\n",
    "      \n",
    "class FuzzyDirGCN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        hidden_channels,\n",
    "        out_channels,\n",
    "        num_layers,\n",
    "        num_nodes,\n",
    "        num_edges,\n",
    "        alpha: Optional[float]=None,\n",
    "        bias=True,\n",
    "        self_loop=True,\n",
    "        mix_self_with_dir=False,\n",
    "        layerwise_theta=False,\n",
    "        normalize=True,\n",
    "        jumping_knowledge=None,\n",
    "        regression=True,\n",
    "        graph_wide=False,\n",
    "        dtype=torch.float,\n",
    "        # encoder_layers=2,\n",
    "        # decoder_layers=2,\n",
    "        # input_dropout=0,\n",
    "        # decoder_dropout=0,\n",
    "        # device=torch.device('cpu'),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.self_loop = self_loop\n",
    "        self.layerwise_theta = layerwise_theta\n",
    "        self.normalize = normalize\n",
    "        self.jumping_knowledge = jumping_knowledge\n",
    "        self.regression=regression\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_edges = num_edges\n",
    "        self.graph_wide = graph_wide\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.get_fuzzy_laplacian = lambda e, t, w: get_fuzzy_laplacian(\n",
    "            e, t, num_nodes, num_edges, w, mix_self_with_dir, 2)\n",
    "\n",
    "        # self.encoder = MLP(\n",
    "        #   in_channels = in_channels, \n",
    "        #   hidden_channels = hidden_channels, \n",
    "        #   out_channels = hidden_channels, \n",
    "        #   num_layers = encoder_layers, \n",
    "        #   bias = True,\n",
    "        #   with_norm = None, \n",
    "        #   with_final_activation = False, \n",
    "        #   dropout = Dropout(p=input_dropout, device=device),\n",
    "        # )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(\n",
    "                FuzzyDirGCNConv(in_channels, hidden_channels, bias=bias, self_loop=self_loop, dtype=dtype))\n",
    "            in_channels = hidden_channels\n",
    "        \n",
    "        #self.readout = FuzzyDirGCNConv(hidden_channels, out_channels, bias=bias, self_loop=self_loop)\n",
    "        self.readout = Linear(hidden_channels, out_channels, bias=bias, weight_initializer='glorot')\n",
    "        #self.readout = torch.nn.Linear(hidden_channels, out_channels, bias=bias, dtype=dtype)\n",
    "\n",
    "        if jumping_knowledge is not None:\n",
    "            input_dim = hidden_channels * num_layers if jumping_knowledge == \"cat\" else hidden_channels\n",
    "            self.lin = Linear(input_dim, out_channels)\n",
    "            self.jump = JumpingKnowledge(mode=jumping_knowledge, channels=hidden_channels, num_layers=num_layers)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        self.readout.reset_parameters()\n",
    "        #self.encoder.reset_parameters()\n",
    "        #self.decoder.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, theta, edge_weight=None, batch=None):\n",
    "        # if x.ndim == 3:\n",
    "        #     num_nodes = x.shape[1]\n",
    "        # elif x.ndim == 2:\n",
    "        #     num_nodes = x.shape[0]\n",
    "        num_nodes = self.num_nodes\n",
    "\n",
    "        if not self.layerwise_theta:\n",
    "            edge_index_frozen, edge_weight_frozen = self.get_fuzzy_laplacian(\n",
    "                edge_index, theta, edge_weight)\n",
    "\n",
    "\n",
    "        x_intermediate = []\n",
    "\n",
    "        #x = self.encoder(x)\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if self.layerwise_theta:\n",
    "                conv_edge_index, conv_edge_weight = self.get_fuzzy_laplacian(\n",
    "                    edge_index, theta[i], edge_weight) \n",
    "            else:\n",
    "                conv_edge_index = edge_index_frozen\n",
    "                conv_edge_weight = edge_weight_frozen\n",
    "\n",
    "            xs = conv(x, conv_edge_index, conv_edge_weight)\n",
    "            if self.self_loop:\n",
    "                x_src_to_dst, x_dst_to_src, x_self = xs\n",
    "                # x_src_to_dst = F.relu(x_src_to_dst)\n",
    "                # x_dst_to_src = F.relu(x_dst_to_src)\n",
    "                # x_self = F.relu(x_self)\n",
    "                if self.alpha is not None:\n",
    "                    x = self.alpha * x_src_to_dst + (1 - self.alpha) * x_dst_to_src + x_self\n",
    "                else:\n",
    "                    x = x_src_to_dst + x_dst_to_src + x_self\n",
    "            else:\n",
    "                x_src_to_dst, x_dst_to_src = xs\n",
    "                # x_src_to_dst = F.relu(x_src_to_dst)\n",
    "                # x_dst_to_src = F.relu(x_dst_to_src)\n",
    "                # x_self = F.relu(x_self)\n",
    "                if self.alpha is not None:\n",
    "                    x = self.alpha * x_src_to_dst + (1 - self.alpha) * x_dst_to_src\n",
    "                else:\n",
    "                    x = x_src_to_dst + x_dst_to_src\n",
    "\n",
    "            if i != len(self.convs) -1 or self.jumping_knowledge is not None:\n",
    "                x = F.relu(x)\n",
    "                if self.normalize:\n",
    "                    x = F.normalize(x, p=2, dim=1)\n",
    "\n",
    "                x_intermediate.append(x)\n",
    "\n",
    "        if self.jumping_knowledge is not None:\n",
    "            x = self.jump(x_intermediate)\n",
    "            x = self.lin(x)\n",
    "        else:\n",
    "            # if self.layerwise_theta:\n",
    "            #     conv_edge_index, conv_edge_weight = self.get_fuzzy_laplacian(\n",
    "            #         edge_index, theta[-1], num_nodes, edge_weight) \n",
    "            # else:\n",
    "            #     conv_edge_index = edge_index_frozen\n",
    "            #     conv_edge_weight = edge_weight_frozen\n",
    "            # xs = self.readout(x, conv_edge_index, conv_edge_weight)\n",
    "            # if self.self_loop:\n",
    "            #     x_src_to_dst, x_dst_to_src, x_self = xs\n",
    "            #     if self.alpha is not None:\n",
    "            #         x = self.alpha * x_src_to_dst + (1 - self.alpha) * x_dst_to_src + x_self\n",
    "            #     else:\n",
    "            #         x = x_src_to_dst + x_dst_to_src + x_self\n",
    "            # else:\n",
    "            #     x_src_to_dst, x_dst_to_src = xs\n",
    "            #     if self.alpha is not None:\n",
    "            #         x = self.alpha * x_src_to_dst + (1 - self.alpha) * x_dst_to_src\n",
    "            #     else:\n",
    "            #         x = x_src_to_dst + x_dst_to_src\n",
    "            x = self.readout(x)\n",
    "        #x = self.decoder(x)\n",
    "        if self.regression:\n",
    "            if self.graph_wide:\n",
    "                assert batch is not None\n",
    "                x = global_mean_pool(x, batch)\n",
    "                return x\n",
    "            else:\n",
    "                print(x.shape, x.dtype)\n",
    "                return x\n",
    "        else:\n",
    "            return F.log_softmax(x, dim=-1)   \n",
    "\n",
    "def masked_regression_loss(\n",
    "    pred: torch.Tensor, \n",
    "    y: torch.Tensor,\n",
    "    mask: Optional[torch.Tensor] = None,\n",
    "):\n",
    "    if mask is not None:\n",
    "        loss = torch.where(\n",
    "            mask,\n",
    "            0.0,\n",
    "            (pred - y).pow(2),\n",
    "        ).sum() / (~mask).sum()\n",
    "    else:\n",
    "        loss = (pred - y).pow(2).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(mp_type, model, optimizer, train_loader, edge_weight, theta=None):\n",
    "    model.train()            \n",
    "    total_loss = 0\n",
    "    for n, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if theta is not None:\n",
    "            pred = model(batch.x, batch.edge_index, theta, edge_weight)\n",
    "        elif mp_type == 'Magnet':\n",
    "            pred = model(batch.x, batch.x, batch.edge_index)\n",
    "        elif mp_type == 'DirGCN':\n",
    "            pred = model(batch.x, batch.edge_index, edge_weight)\n",
    "        elif mp_type == 'DirGAT':\n",
    "            _edge_weight = torch.ones(batch.edge_index.shape[1], device=batch.x.device)\n",
    "            pred = model(batch.x, batch.edge_index, _edge_weight)\n",
    "        else:\n",
    "            pred = model(batch.x, batch.edge_index)\n",
    "        loss = masked_regression_loss(pred, batch.y, batch.mask)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(theta, list):\n",
    "                for t in theta:\n",
    "                    t.clamp_(0, torch.pi/2)\n",
    "            elif isinstance(theta, torch.Tensor):\n",
    "                theta.clamp_(0, torch.pi/2)\n",
    "    return total_loss / (train_loader.batch_size * (n+1))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mp_type, model, loader, edge_weight, theta=None):\n",
    "    model.eval()\n",
    "\n",
    "    total_error = 0\n",
    "    for n, batch in enumerate(loader):\n",
    "        if theta is not None:\n",
    "            pred = model(batch.x, batch.edge_index, theta, edge_weight)\n",
    "        elif mp_type == 'Magnet':\n",
    "            pred = model(batch.x, batch.x, batch.edge_index)\n",
    "        elif mp_type == 'DirGCN':\n",
    "            pred = model(batch.x, batch.edge_index, edge_weight)\n",
    "        elif mp_type == 'DirGAT':\n",
    "            _edge_weight = torch.ones(batch.edge_index.shape[1], device=batch.x.device)\n",
    "            pred = model(batch.x, batch.edge_index, _edge_weight)\n",
    "        else:\n",
    "            pred = model(batch.x, batch.edge_index)\n",
    "        total_error += masked_regression_loss(pred, batch.y, batch.mask).item()\n",
    "    return total_error / (n + 1)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "train_loader, val_loader, test_loader, info = get_graph_ensemble_dataset('perturb_seq', device='cuda:0', undirected=False)\n",
    "num_nodes = info['num_nodes']\n",
    "num_edges = info['num_edges']\n",
    "in_channels = info['in_channels']\n",
    "out_channels = info['out_channels']\n",
    "\n",
    "model = FuzzyDirGCN(\n",
    "    1, 32, 1, 4, \n",
    "    num_nodes=num_nodes, num_edges=num_edges, \n",
    "    normalize=False, layerwise_theta=False, alpha=0.5,\n",
    "    self_loop=False, jumping_knowledge=None,\n",
    ").to(device)\n",
    "\n",
    "# import importlib\n",
    "# import model\n",
    "\n",
    "# # Reload the entire module\n",
    "# importlib.reload(model)\n",
    "# from model import FuzzyDirGCN as FDG2\n",
    "# model = FDG2(\n",
    "#     in_channels=1, \n",
    "#     hidden_channels=32, \n",
    "#     out_channels=1, \n",
    "#     num_layers=4,\n",
    "#     num_nodes=info['num_nodes'],\n",
    "#     num_edges=info['num_edges'],\n",
    "#     alpha=0.5,\n",
    "#     normalize=False,\n",
    "#     self_feature_transform=False,\n",
    "#     self_loop=False,\n",
    "#     layer_wise_theta=False,\n",
    "#     regression=True,\n",
    "#     dropout_rate=0,\n",
    "#     jumping_knowledge=None).to(device) \n",
    "model.reset_parameters()\n",
    "theta = torch.tensor([np.pi/4] * edge_index.shape[1], requires_grad=True, device=device)\n",
    "\n",
    "opt_theta = torch.tensor([torch.pi/4]*edge_index.shape[1], device=device, requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = 5000\n",
    "best_val_loss = torch.inf\n",
    "num_nondecreasing_step = 0\n",
    "patience = 30\n",
    "\n",
    "lr = 1e-3\n",
    "theta_lr = 5e-4\n",
    "mp_type = 'fuzzy'\n",
    "\n",
    "edge_weight = torch.tensor([1.] * edge_index.shape[1], requires_grad=False, device=device)\n",
    "param_groups = [{'params': model.parameters(), 'lr': lr}]\n",
    "param_groups.append({'params': opt_theta, 'lr': theta_lr})\n",
    "optimizer = torch.optim.Adam(param_groups)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(mp_type, model, optimizer, train_loader, edge_weight, opt_theta)\n",
    "    val_loss = test(mp_type, model, val_loader, edge_weight, opt_theta)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_test_loss = test(mp_type, model, test_loader, edge_weight, opt_theta)\n",
    "        num_nondecreasing_step = 0\n",
    "    else:\n",
    "        num_nondecreasing_step += 1\n",
    "\n",
    "    if num_nondecreasing_step > patience:\n",
    "        break\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'epoch: {epoch}, tr/val loss: {train_loss:.5f}/{val_loss:.5f}/{best_test_loss:.5f}, # non-decreasing steps: {num_nondecreasing_step}')\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.plot(opt_theta.detach().cpu().numpy(), 'o')\n",
    "        plt.ylim(0, np.pi/2)\n",
    "        plt.show()\n",
    "\n",
    "print(f'best test loss: {best_test_loss:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29edb313-5373-4835-b508-9b2a5d4eb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_fuzzy_laplacian as gfl2\n",
    "\n",
    "ei, ew = get_fuzzy_laplacian(edge_index, opt_theta, num_nodes, num_edges, edge_weight)\n",
    "ei2, ew2 = gfl2(edge_index, opt_theta, num_nodes, num_edges, edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "073008d0-1cfc-4245-8f8d-b4b2b592487a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5933, torch.Size([2, 5933]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "train_loader, val_loader, test_loader, info = get_graph_ensemble_dataset(\n",
    "    'perturb_seq', device=device, undirected=False)\n",
    "info['num_edges'], edge_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ed4c1c-0d29-4051-b51d-c566b78805c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, mask = get_classification_dataset('cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e7db4d7-7ff0-4d45-b90e-57fb05dbc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../datasets/perturb_seq/Replogle-gwps_training_data_with_three_splits.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53a49863-5f1c-497d-a99e-841dbc10c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training_data', 'val_data', 'test_data', 'training_data_count', 'val_data_count', 'test_data_count', 'graph_info'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d818485-663f-4f6c-bce3-83143a94570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1992, 1993, 1995],\n",
       "       [  21,  244,  473, ..., 1998, 1998, 1998]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['graph_info'][3]['edge_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecce38ea-bc43-44bc-87cf-fc78478fed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    {'train_data': data[0]['training_data_count'],\n",
    "     'val_data': data[0]['val_data_count'],\n",
    "     'test_data': data[0]['test_data_count'],\n",
    "     'edge_index': data[0]['graph_info'][3]['edge_indices']},\n",
    "    open('../datasets/perturb_seq/Replogle-gwps.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "628c7401-fe78-4ec3-a326-8de102ec606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, pe = get_graph_ensemble_dataset(\n",
    "    'lattice', undirected=False, pe_type='eigenvector', pe_dim=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1991e07c-a382-4bd0-b87c-81e3a9720404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_graph_ensemble_dataset(\n",
    "    'perturb_seq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71ba1ddd-8f84-47eb-bd06-0ed1475d9e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[32000, 1], edge_index=[2, 94928], y=[32000, 1], mask=[32000], batch=[32000], ptr=[17])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "767832c0-a964-4581-bf7d-9ae4488f32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, meta_data = get_graph_ensemble_dataset(\n",
    "    'power_grid', '/sahandlab/Team/directifying_graph/ICLR/datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fbc38-5d89-462d-aebe-7e937db0df0c",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b86c4e-c39f-4879-a908-eee8e77108eb",
   "metadata": {},
   "source": [
    "### 1. Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a263678-d3a3-48c7-9186-900db1473b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# CoED\n",
    "device = torch.device('cuda:0')\n",
    "data, (train_mask, val_mask, test_mask) = get_classification_dataset('cora', device='cuda:0')\n",
    "\n",
    "adj = to_dense_adj(data.edge_index)[0]\n",
    "print(adj[np.diag_indices(len(adj))].sum())\n",
    "#adj.fill_diagonal_(0.0)\n",
    "\n",
    "src_to_dst_edge, dst_to_src_edge, theta = get_edge_index_and_theta(adj)\n",
    "theta = theta.float()\n",
    "edge_index = src_to_dst_edge #.to(device)\n",
    "edge_weight = torch.ones(edge_index.shape[1]) # .to(device)\n",
    "\n",
    "num_nodes, num_edges = data.x.shape[0], edge_index.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e646b2a4-666e-41d1-bf8f-df3c42f15052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, model, optimizer, edge_index, theta, edge_weight, mask, index=None):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    if index is not None:\n",
    "        loss = F.nll_loss( #F.cross_entropy(\n",
    "            model(x, edge_index, theta, edge_weight)[mask[:, index]], \n",
    "            y[mask[:, index]])\n",
    "    else:\n",
    "        loss = F.nll_loss( #F.cross_entropy(\n",
    "            model(x, edge_index, theta, edge_weight)[mask], \n",
    "            #model(x, edge_index)[mask], \n",
    "            y[mask])  \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(x, y, model, optimizer, edge_index, theta, edge_weight, masks, index):\n",
    "    model.eval()\n",
    "    log_probs, accs = model(x, edge_index, theta, edge_weight), []\n",
    "    for mask in masks:\n",
    "        if index is not None:\n",
    "            pred = log_probs[mask[:, index]].max(1)[1]\n",
    "            acc = pred.eq(y[mask[:, index]]).sum().item() / mask[:, index].sum().item()\n",
    "        else:\n",
    "            pred = log_probs[mask].max(1)[1]\n",
    "            acc = pred.eq(y[mask]).sum().item() / mask.sum().item()            \n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac60dd-17ee-4392-8e14-49e71eeb9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 | Epoch: 050, Loss: 1.68637, Train: 0.2936, Val: 0.2990, Best: 0.3903, early_stopping: 42\n",
      "index: 0 | Epoch: 100, Loss: 1.14311, Train: 0.7391, Val: 0.7274, Best: 0.7143, early_stopping: 0\n",
      "index: 0 | Epoch: 150, Loss: 0.62075, Train: 0.8683, Val: 0.8141, Best: 0.8129, early_stopping: 3\n",
      "index: 0 | Epoch: 200, Loss: 0.37037, Train: 0.9304, Val: 0.8518, Best: 0.827, early_stopping: 0\n",
      "index: 0 | Epoch: 250, Loss: 0.24962, Train: 0.9497, Val: 0.8656, Best: 0.8451, early_stopping: 0\n",
      "index: 0 | Epoch: 300, Loss: 0.18680, Train: 0.9664, Val: 0.8643, Best: 0.8491, early_stopping: 46\n",
      "index: 0 | Epoch: 350, Loss: 0.15104, Train: 0.9757, Val: 0.8681, Best: 0.8592, early_stopping: 43\n",
      "index: 0 | Epoch: 400, Loss: 0.12171, Train: 0.9799, Val: 0.8643, Best: 0.8592, early_stopping: 93\n",
      "index: 0 | Epoch: 450, Loss: 0.10308, Train: 0.9857, Val: 0.8631, Best: 0.8592, early_stopping: 143\n",
      "index: 0 | Epoch: 500, Loss: 0.08932, Train: 0.9899, Val: 0.8606, Best: 0.8592, early_stopping: 193\n",
      "index: 1 | Epoch: 050, Loss: 1.69117, Train: 0.2836, Val: 0.3028, Best: 0.2958, early_stopping: 49\n",
      "index: 1 | Epoch: 100, Loss: 1.13388, Train: 0.7626, Val: 0.7374, Best: 0.7223, early_stopping: 1\n",
      "index: 1 | Epoch: 150, Loss: 0.64784, Train: 0.8482, Val: 0.7940, Best: 0.7948, early_stopping: 0\n",
      "index: 1 | Epoch: 200, Loss: 0.39802, Train: 0.9304, Val: 0.8518, Best: 0.8652, early_stopping: 2\n",
      "index: 1 | Epoch: 250, Loss: 0.26142, Train: 0.9471, Val: 0.8731, Best: 0.8833, early_stopping: 14\n",
      "index: 1 | Epoch: 300, Loss: 0.19482, Train: 0.9555, Val: 0.8593, Best: 0.8833, early_stopping: 64\n",
      "index: 1 | Epoch: 350, Loss: 0.15729, Train: 0.9757, Val: 0.8631, Best: 0.8833, early_stopping: 114\n",
      "index: 1 | Epoch: 400, Loss: 0.11772, Train: 0.9824, Val: 0.8643, Best: 0.8833, early_stopping: 164\n",
      "index: 2 | Epoch: 050, Loss: 1.68373, Train: 0.2953, Val: 0.2802, Best: 0.3038, early_stopping: 49\n",
      "index: 2 | Epoch: 100, Loss: 1.11727, Train: 0.7584, Val: 0.7111, Best: 0.7324, early_stopping: 0\n",
      "index: 2 | Epoch: 150, Loss: 0.60315, Train: 0.8775, Val: 0.8116, Best: 0.833, early_stopping: 1\n",
      "index: 2 | Epoch: 200, Loss: 0.36033, Train: 0.9304, Val: 0.8555, Best: 0.8813, early_stopping: 0\n",
      "index: 2 | Epoch: 250, Loss: 0.24722, Train: 0.9564, Val: 0.8631, Best: 0.8934, early_stopping: 12\n",
      "index: 2 | Epoch: 300, Loss: 0.18023, Train: 0.9673, Val: 0.8606, Best: 0.8934, early_stopping: 62\n",
      "index: 2 | Epoch: 350, Loss: 0.13838, Train: 0.9765, Val: 0.8543, Best: 0.8934, early_stopping: 112\n",
      "index: 2 | Epoch: 400, Loss: 0.11473, Train: 0.9832, Val: 0.8518, Best: 0.8934, early_stopping: 162\n",
      "index: 3 | Epoch: 050, Loss: 1.69272, Train: 0.2911, Val: 0.3153, Best: 0.2877, early_stopping: 43\n",
      "index: 3 | Epoch: 100, Loss: 1.15857, Train: 0.7601, Val: 0.7148, Best: 0.7243, early_stopping: 0\n",
      "index: 3 | Epoch: 150, Loss: 0.62818, Train: 0.8733, Val: 0.8028, Best: 0.8048, early_stopping: 0\n",
      "index: 3 | Epoch: 200, Loss: 0.38922, Train: 0.9018, Val: 0.8342, Best: 0.841, early_stopping: 0\n",
      "index: 3 | Epoch: 250, Loss: 0.27264, Train: 0.9413, Val: 0.8681, Best: 0.8632, early_stopping: 8\n",
      "index: 3 | Epoch: 300, Loss: 0.20771, Train: 0.9555, Val: 0.8706, Best: 0.8612, early_stopping: 16\n",
      "index: 3 | Epoch: 350, Loss: 0.16425, Train: 0.9656, Val: 0.8681, Best: 0.8612, early_stopping: 66\n",
      "index: 3 | Epoch: 400, Loss: 0.13237, Train: 0.9740, Val: 0.8681, Best: 0.8612, early_stopping: 116\n",
      "index: 3 | Epoch: 450, Loss: 0.11302, Train: 0.9807, Val: 0.8656, Best: 0.8612, early_stopping: 166\n",
      "index: 4 | Epoch: 050, Loss: 1.69220, Train: 0.2836, Val: 0.3103, Best: 0.2817, early_stopping: 49\n",
      "index: 4 | Epoch: 100, Loss: 1.10138, Train: 0.7676, Val: 0.7487, Best: 0.7586, early_stopping: 0\n",
      "index: 4 | Epoch: 150, Loss: 0.59742, Train: 0.8750, Val: 0.8141, Best: 0.8169, early_stopping: 2\n",
      "index: 4 | Epoch: 200, Loss: 0.34558, Train: 0.9354, Val: 0.8555, Best: 0.8571, early_stopping: 6\n",
      "index: 4 | Epoch: 250, Loss: 0.25208, Train: 0.9539, Val: 0.8643, Best: 0.8632, early_stopping: 8\n",
      "index: 4 | Epoch: 300, Loss: 0.18463, Train: 0.9639, Val: 0.8656, Best: 0.8612, early_stopping: 15\n",
      "index: 4 | Epoch: 350, Loss: 0.14163, Train: 0.9757, Val: 0.8668, Best: 0.8592, early_stopping: 30\n",
      "index: 4 | Epoch: 400, Loss: 0.11613, Train: 0.9824, Val: 0.8668, Best: 0.8632, early_stopping: 42\n",
      "index: 4 | Epoch: 450, Loss: 0.10091, Train: 0.9883, Val: 0.8618, Best: 0.8632, early_stopping: 92\n",
      "index: 4 | Epoch: 500, Loss: 0.08790, Train: 0.9924, Val: 0.8643, Best: 0.8632, early_stopping: 142\n",
      "index: 4 | Epoch: 550, Loss: 0.07695, Train: 0.9933, Val: 0.8606, Best: 0.8632, early_stopping: 192\n",
      "index: 5 | Epoch: 050, Loss: 1.67097, Train: 0.3062, Val: 0.2651, Best: 0.3038, early_stopping: 42\n",
      "index: 5 | Epoch: 100, Loss: 1.12588, Train: 0.7576, Val: 0.6985, Best: 0.7082, early_stopping: 0\n",
      "index: 5 | Epoch: 150, Loss: 0.63100, Train: 0.8683, Val: 0.8065, Best: 0.829, early_stopping: 0\n",
      "index: 5 | Epoch: 200, Loss: 0.39423, Train: 0.9295, Val: 0.8593, Best: 0.8592, early_stopping: 5\n",
      "index: 5 | Epoch: 250, Loss: 0.26740, Train: 0.9488, Val: 0.8681, Best: 0.8672, early_stopping: 26\n",
      "index: 5 | Epoch: 300, Loss: 0.20088, Train: 0.9648, Val: 0.8681, Best: 0.8672, early_stopping: 76\n",
      "index: 5 | Epoch: 350, Loss: 0.15587, Train: 0.9757, Val: 0.8618, Best: 0.8672, early_stopping: 126\n",
      "index: 5 | Epoch: 400, Loss: 0.11499, Train: 0.9807, Val: 0.8593, Best: 0.8672, early_stopping: 176\n",
      "index: 6 | Epoch: 050, Loss: 1.69908, Train: 0.2928, Val: 0.2852, Best: 0.3018, early_stopping: 45\n",
      "index: 6 | Epoch: 100, Loss: 1.15998, Train: 0.7383, Val: 0.7437, Best: 0.7223, early_stopping: 0\n",
      "index: 6 | Epoch: 150, Loss: 0.63854, Train: 0.8624, Val: 0.8405, Best: 0.8129, early_stopping: 1\n",
      "index: 6 | Epoch: 200, Loss: 0.38234, Train: 0.9253, Val: 0.8832, Best: 0.841, early_stopping: 10\n",
      "index: 6 | Epoch: 250, Loss: 0.25526, Train: 0.9488, Val: 0.8857, Best: 0.839, early_stopping: 27\n",
      "index: 6 | Epoch: 300, Loss: 0.19454, Train: 0.9639, Val: 0.8882, Best: 0.8451, early_stopping: 22\n",
      "index: 6 | Epoch: 350, Loss: 0.15024, Train: 0.9773, Val: 0.8907, Best: 0.8531, early_stopping: 27\n",
      "index: 6 | Epoch: 400, Loss: 0.11861, Train: 0.9849, Val: 0.8907, Best: 0.8531, early_stopping: 77\n",
      "index: 6 | Epoch: 450, Loss: 0.10113, Train: 0.9883, Val: 0.8882, Best: 0.8531, early_stopping: 127\n",
      "index: 6 | Epoch: 500, Loss: 0.09078, Train: 0.9891, Val: 0.8832, Best: 0.8531, early_stopping: 177\n",
      "index: 7 | Epoch: 050, Loss: 1.66675, Train: 0.3255, Val: 0.3015, Best: 0.4024, early_stopping: 44\n",
      "index: 7 | Epoch: 100, Loss: 1.12377, Train: 0.7190, Val: 0.6884, Best: 0.674, early_stopping: 0\n",
      "index: 7 | Epoch: 150, Loss: 0.63347, Train: 0.8649, Val: 0.8291, Best: 0.831, early_stopping: 5\n",
      "index: 7 | Epoch: 200, Loss: 0.41416, Train: 0.9237, Val: 0.8543, Best: 0.8652, early_stopping: 4\n",
      "index: 7 | Epoch: 250, Loss: 0.27779, Train: 0.9497, Val: 0.8769, Best: 0.8753, early_stopping: 1\n",
      "index: 7 | Epoch: 300, Loss: 0.19984, Train: 0.9631, Val: 0.8844, Best: 0.8773, early_stopping: 21\n",
      "index: 7 | Epoch: 350, Loss: 0.16659, Train: 0.9732, Val: 0.8807, Best: 0.8753, early_stopping: 36\n",
      "index: 7 | Epoch: 400, Loss: 0.12944, Train: 0.9773, Val: 0.8744, Best: 0.8753, early_stopping: 86\n",
      "index: 7 | Epoch: 450, Loss: 0.11595, Train: 0.9832, Val: 0.8719, Best: 0.8753, early_stopping: 136\n",
      "index: 7 | Epoch: 500, Loss: 0.09204, Train: 0.9857, Val: 0.8693, Best: 0.8753, early_stopping: 186\n",
      "index: 8 | Epoch: 050, Loss: 1.68158, Train: 0.3054, Val: 0.3003, Best: 0.3803, early_stopping: 39\n",
      "index: 8 | Epoch: 100, Loss: 1.14939, Train: 0.7584, Val: 0.6947, Best: 0.6398, early_stopping: 0\n",
      "index: 8 | Epoch: 150, Loss: 0.63284, Train: 0.8633, Val: 0.7927, Best: 0.7706, early_stopping: 0\n",
      "index: 8 | Epoch: 200, Loss: 0.37482, Train: 0.9346, Val: 0.8430, Best: 0.8471, early_stopping: 6\n",
      "index: 8 | Epoch: 250, Loss: 0.24340, Train: 0.9564, Val: 0.8467, Best: 0.8571, early_stopping: 31\n",
      "index: 8 | Epoch: 300, Loss: 0.17585, Train: 0.9723, Val: 0.8518, Best: 0.8632, early_stopping: 1\n",
      "index: 8 | Epoch: 350, Loss: 0.13263, Train: 0.9790, Val: 0.8505, Best: 0.8672, early_stopping: 10\n",
      "index: 8 | Epoch: 400, Loss: 0.11719, Train: 0.9832, Val: 0.8518, Best: 0.8672, early_stopping: 60\n",
      "index: 8 | Epoch: 450, Loss: 0.09307, Train: 0.9857, Val: 0.8492, Best: 0.8672, early_stopping: 110\n",
      "index: 8 | Epoch: 500, Loss: 0.08545, Train: 0.9866, Val: 0.8480, Best: 0.8672, early_stopping: 160\n",
      "index: 9 | Epoch: 050, Loss: 1.69368, Train: 0.2844, Val: 0.3040, Best: 0.3119, early_stopping: 0\n",
      "index: 9 | Epoch: 100, Loss: 1.11476, Train: 0.7500, Val: 0.7148, Best: 0.7384, early_stopping: 0\n",
      "index: 9 | Epoch: 150, Loss: 0.60332, Train: 0.8826, Val: 0.8266, Best: 0.8431, early_stopping: 0\n"
     ]
    }
   ],
   "source": [
    "in_channels = data.x.shape[-1]\n",
    "out_channels = data.y.max().item() + 1\n",
    "hidden_channels = 128\n",
    "num_layers = 2\n",
    "lr = 5e-4\n",
    "wd = 1e-4\n",
    "dropout_rate = 0.5\n",
    "alpha = 0.\n",
    "normalize = False\n",
    "jumping_knolwedge = None\n",
    "self_loop = True\n",
    "self_feature_transform = False\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "test_accs = []     \n",
    "\n",
    "for index in range(10):\n",
    "\n",
    "    model = FuzzyDirGCN(\n",
    "        in_channels=data.x.shape[-1], \n",
    "        hidden_channels=hidden_channels, \n",
    "        out_channels=data.y.max().item() + 1, \n",
    "        num_layers=num_layers,\n",
    "        num_nodes=num_nodes,\n",
    "        num_edges=num_edges,\n",
    "        alpha=alpha,\n",
    "        normalize=normalize,\n",
    "        self_feature_transform=self_feature_transform,\n",
    "        self_loop=self_loop,\n",
    "        layer_wise_theta=False,\n",
    "        regression=False,\n",
    "        dropout_rate=dropout_rate,\n",
    "        jumping_knowledge=jumping_knolwedge).to(device) \n",
    "    model.reset_parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_test_acc = 0.0\n",
    "    n_non_decreasing_step = 0\n",
    "\n",
    "    for epoch in range(1, 1000):\n",
    "        tr_loss = train(\n",
    "            data.x, data.y, model, optimizer, \n",
    "            edge_index, theta, edge_weight.to(device), \n",
    "            train_mask, index)\n",
    "        train_acc, val_acc, test_acc = test(\n",
    "            data.x, data.y, model, optimizer, \n",
    "            edge_index, theta, edge_weight.to(device), \n",
    "            (train_mask, val_mask, test_mask), index)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            n_non_decreasing_step = 0\n",
    "        else:\n",
    "            n_non_decreasing_step += 1\n",
    "        \n",
    "        if n_non_decreasing_step > 200:\n",
    "            break\n",
    "    \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'index: {index} | '\n",
    "                  f'Epoch: {epoch:03d}, Loss: {tr_loss:.5f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "                  f'Best: {best_test_acc:.4}, early_stopping: {n_non_decreasing_step}')\n",
    "\n",
    "        \n",
    "    \n",
    "    # for n, p in model.named_parameters():\n",
    "    #     print(n, p)\n",
    "    test_accs.append(best_test_acc)\n",
    "    # plt.figure(figsize=(4, 3))\n",
    "    # plt.plot(theta.detach().cpu().numpy(), 'o')\n",
    "    # plt.ylim(0, np.pi/2)\n",
    "    # plt.show()\n",
    "        \n",
    "print(f'test acc: {np.mean(test_accs):.6f} +/- {np.std(test_accs):.6f}')\n",
    "print(test_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37898da4-4dc0-4b22-8699-f5d58ab2a185",
   "metadata": {},
   "source": [
    "### Magnet cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d5e6bbc-ae99-40c6-9405-6ac60bb6293a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Magnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      4\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMagnet\u001b[49m(\n\u001b[1;32m      7\u001b[0m     num_features\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      8\u001b[0m     hidden\u001b[38;5;241m=\u001b[39mhidden_channels,\n\u001b[1;32m      9\u001b[0m     label_dim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     10\u001b[0m     K\u001b[38;5;241m=\u001b[39mK,\n\u001b[1;32m     11\u001b[0m     activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     trainable_q\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     layer\u001b[38;5;241m=\u001b[39mn_layers,\n\u001b[1;32m     14\u001b[0m     q\u001b[38;5;241m=\u001b[39mq,\n\u001b[1;32m     15\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Magnet' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_channels = 32\n",
    "num_layers = 1\n",
    "K = 2\n",
    "q = 0\n",
    "\n",
    "model = Magnet(\n",
    "    num_features=data.x.shape[-1],\n",
    "    hidden=hidden_channels,\n",
    "    label_dim=data.y.max().item() + 1, \n",
    "    K=K,\n",
    "    activation=True,\n",
    "    trainable_q=False,\n",
    "    layer=n_layers,\n",
    "    q=q,\n",
    "    dropout=0.5,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe2059c3-76fc-4dc1-9d68-196249f77e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta = pickle.load(open('lattice_top_theta.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "635f2b94-6769-445e-97ea-d838080abd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.73650855, 1.5214065 , 0.58792776, ..., 0.48760566, 0.1626729 ,\n",
       "        1.057236  ], dtype=float32),\n",
       " array([0.71865016, 1.5378263 , 0.55153984, ..., 0.4664467 , 0.29270455,\n",
       "        0.6464112 ], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "137a5b97-b611-419e-8dd2-8437f8696825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 5,\n",
       " 'hidden_dimension': 32,\n",
       " 'learning_rate': 0.001,\n",
       " 'theta_learning_rate': 0.01,\n",
       " 'layer_wise_theta': True,\n",
       " 'weight_decay': 0,\n",
       " 'dropout_rate': 0,\n",
       " 'self_loop': False,\n",
       " 'alpha': 0.5,\n",
       " 'normalize': False,\n",
       " 'jumping_knowledge': 'None',\n",
       " 'self_feature_transform': True,\n",
       " 'patience': 50}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "best_params_file = f\"best_hyperparams_synthetic_ensemble.yaml\"\n",
    "with open(best_params_file, \"r\") as file:\n",
    "    hyperparams = yaml.safe_load(file)\n",
    "\n",
    "hyperparams['CoED']['grn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52bf093b-bdfe-4fde-a175-77f7263fde9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layers 5\n",
      "hidden_dimension 32\n",
      "learning_rate 0.001\n",
      "theta_learning_rate 0.01\n",
      "layer_wise_theta True\n",
      "weight_decay 0\n",
      "dropout_rate 0\n",
      "self_loop False\n",
      "alpha 0.5\n",
      "normalize False\n",
      "jumping_knowledge None\n",
      "self_feature_transform True\n",
      "patience 50\n"
     ]
    }
   ],
   "source": [
    "for key, value in hyperparams['CoED']['grn'].items():\n",
    "    print(key, value)\n",
    "    # if hasattr(args, key):\n",
    "    #     value = None if value == \"None\" else value\n",
    "    #     setattr(args, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54369f2f-d6f9-42db-8ee5-0dcd0d6e04ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2-gpu",
   "language": "python",
   "name": "your_environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
