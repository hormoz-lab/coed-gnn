{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "594635ab-9ad8-4d03-b695-b484c3a35062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b43144f0-1963-40e0-bd23-8674993897a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch.nn.functional as F\n",
    "from utils import get_edge_index_and_theta\n",
    "from model import FuzzyDirGCN\n",
    "import torch\n",
    "\n",
    "import importlib\n",
    "import utils.data_loading\n",
    "\n",
    "# Reload the entire module\n",
    "importlib.reload(utils.data_loading)\n",
    "\n",
    "# Now, re-import the specific function\n",
    "from utils.data_loading import (\n",
    "    get_classification_dataset,\n",
    "    get_graph_ensemble_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e92df8f-d977-42e0-a515-4d354d9fdb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set the seed for Python's built-in random module\n",
    "    # Set the seed for NumPy (if you're using it)\n",
    "    np.random.seed(seed)\n",
    "    # Set the seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    # If using a GPU, ensure that all operations are deterministic\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ed4c1c-0d29-4051-b51d-c566b78805c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, mask = get_classification_dataset('cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e7db4d7-7ff0-4d45-b90e-57fb05dbc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../datasets/perturb_seq/Replogle-gwps_training_data_with_three_splits.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53a49863-5f1c-497d-a99e-841dbc10c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training_data', 'val_data', 'test_data', 'training_data_count', 'val_data_count', 'test_data_count', 'graph_info'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d818485-663f-4f6c-bce3-83143a94570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1992, 1993, 1995],\n",
       "       [  21,  244,  473, ..., 1998, 1998, 1998]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['graph_info'][3]['edge_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecce38ea-bc43-44bc-87cf-fc78478fed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    {'train_data': data[0]['training_data_count'],\n",
    "     'val_data': data[0]['val_data_count'],\n",
    "     'test_data': data[0]['test_data_count'],\n",
    "     'edge_index': data[0]['graph_info'][3]['edge_indices']},\n",
    "    open('../datasets/perturb_seq/Replogle-gwps.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "628c7401-fe78-4ec3-a326-8de102ec606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, pe = get_graph_ensemble_dataset(\n",
    "    'lattice', undirected=False, pe_type='eigenvector', pe_dim=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1991e07c-a382-4bd0-b87c-81e3a9720404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_graph_ensemble_dataset(\n",
    "    'perturb_seq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71ba1ddd-8f84-47eb-bd06-0ed1475d9e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[32000, 1], edge_index=[2, 94928], y=[32000, 1], mask=[32000], batch=[32000], ptr=[17])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "767832c0-a964-4581-bf7d-9ae4488f32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, meta_data = get_graph_ensemble_dataset(\n",
    "    'power_grid', '/sahandlab/Team/directifying_graph/ICLR/datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fbc38-5d89-462d-aebe-7e937db0df0c",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b86c4e-c39f-4879-a908-eee8e77108eb",
   "metadata": {},
   "source": [
    "### 1. Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a263678-d3a3-48c7-9186-900db1473b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16., device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "# CoED\n",
    "device = torch.device('cuda:1')\n",
    "data, (train_mask, val_mask, test_mask) = get_classification_dataset('wisconsin', device='cuda:1')\n",
    "\n",
    "adj = to_dense_adj(data.edge_index)[0]\n",
    "print(adj[np.diag_indices(len(adj))].sum())\n",
    "#adj.fill_diagonal_(0.0)\n",
    "\n",
    "src_to_dst_edge, dst_to_src_edge, theta = get_edge_index_and_theta(adj)\n",
    "theta = theta.float()\n",
    "edge_index = src_to_dst_edge #.to(device)\n",
    "edge_weight = torch.ones(edge_index.shape[1]) # .to(device)\n",
    "\n",
    "num_nodes, num_edges = data.x.shape[0], edge_index.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e646b2a4-666e-41d1-bf8f-df3c42f15052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, model, optimizer, edge_index, theta, edge_weight, mask, index=None):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    if index is not None:\n",
    "        loss = F.nll_loss( #F.cross_entropy(\n",
    "            model(x, edge_index, theta, edge_weight)[mask[:, index]], \n",
    "            #model(x, edge_index)[mask[:, index]], \n",
    "            y[mask[:, index]])\n",
    "    else:\n",
    "        loss = F.nll_loss( #F.cross_entropy(\n",
    "            model(x, edge_index, theta, edge_weight)[mask], \n",
    "            #model(x, edge_index)[mask], \n",
    "            y[mask])  \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(x, y, model, optimizer, edge_index, theta, edge_weight, masks, index):\n",
    "    model.eval()\n",
    "    log_probs, accs = model(x, edge_index, theta, edge_weight), []\n",
    "    #log_probs, accs = model(x, edge_index), []\n",
    "    for mask in masks:\n",
    "        if index is not None:\n",
    "            pred = log_probs[mask[:, index]].max(1)[1]\n",
    "            acc = pred.eq(y[mask[:, index]]).sum().item() / mask[:, index].sum().item()\n",
    "        else:\n",
    "            pred = log_probs[mask].max(1)[1]\n",
    "            acc = pred.eq(y[mask]).sum().item() / mask.sum().item()            \n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cac60dd-17ee-4392-8e14-49e71eeb9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 | Epoch: 050, Loss: 0.05403, Train: 1.0000, Val: 0.8875, Best: 0.7647, early_stopping: 7\n",
      "index: 0 | Epoch: 100, Loss: 0.04807, Train: 1.0000, Val: 0.8625, Best: 0.7843, early_stopping: 40\n",
      "index: 0 | Epoch: 150, Loss: 0.04378, Train: 1.0000, Val: 0.8250, Best: 0.7843, early_stopping: 90\n",
      "index: 0 | Epoch: 200, Loss: 0.03632, Train: 1.0000, Val: 0.8750, Best: 0.7843, early_stopping: 140\n",
      "index: 0 | Epoch: 250, Loss: 0.05496, Train: 1.0000, Val: 0.8500, Best: 0.7843, early_stopping: 190\n",
      "index: 1 | Epoch: 050, Loss: 0.07993, Train: 0.9917, Val: 0.7625, Best: 0.9216, early_stopping: 19\n",
      "index: 1 | Epoch: 100, Loss: 0.06236, Train: 0.9917, Val: 0.8000, Best: 0.902, early_stopping: 18\n",
      "index: 1 | Epoch: 150, Loss: 0.08245, Train: 1.0000, Val: 0.7625, Best: 0.902, early_stopping: 68\n",
      "index: 1 | Epoch: 200, Loss: 0.04684, Train: 1.0000, Val: 0.8125, Best: 0.902, early_stopping: 118\n",
      "index: 1 | Epoch: 250, Loss: 0.06326, Train: 1.0000, Val: 0.8000, Best: 0.902, early_stopping: 168\n",
      "index: 2 | Epoch: 050, Loss: 0.06826, Train: 1.0000, Val: 0.7875, Best: 0.8039, early_stopping: 30\n",
      "index: 2 | Epoch: 100, Loss: 0.04477, Train: 1.0000, Val: 0.8125, Best: 0.8431, early_stopping: 29\n",
      "index: 2 | Epoch: 150, Loss: 0.04967, Train: 1.0000, Val: 0.8375, Best: 0.8235, early_stopping: 27\n",
      "index: 2 | Epoch: 200, Loss: 0.05144, Train: 1.0000, Val: 0.8125, Best: 0.8431, early_stopping: 12\n",
      "index: 2 | Epoch: 250, Loss: 0.05000, Train: 1.0000, Val: 0.8250, Best: 0.8431, early_stopping: 62\n",
      "index: 2 | Epoch: 300, Loss: 0.07793, Train: 1.0000, Val: 0.8375, Best: 0.8431, early_stopping: 112\n",
      "index: 2 | Epoch: 350, Loss: 0.04975, Train: 1.0000, Val: 0.8250, Best: 0.8431, early_stopping: 162\n",
      "index: 3 | Epoch: 050, Loss: 0.06800, Train: 1.0000, Val: 0.7875, Best: 0.902, early_stopping: 3\n",
      "index: 3 | Epoch: 100, Loss: 0.06166, Train: 1.0000, Val: 0.7750, Best: 0.902, early_stopping: 27\n",
      "index: 3 | Epoch: 150, Loss: 0.05428, Train: 1.0000, Val: 0.8500, Best: 0.902, early_stopping: 77\n",
      "index: 3 | Epoch: 200, Loss: 0.04654, Train: 1.0000, Val: 0.8000, Best: 0.902, early_stopping: 127\n",
      "index: 3 | Epoch: 250, Loss: 0.08809, Train: 1.0000, Val: 0.7875, Best: 0.902, early_stopping: 177\n",
      "index: 4 | Epoch: 050, Loss: 0.09091, Train: 1.0000, Val: 0.8250, Best: 0.8627, early_stopping: 0\n",
      "index: 4 | Epoch: 100, Loss: 0.06478, Train: 1.0000, Val: 0.8250, Best: 0.8627, early_stopping: 50\n",
      "index: 4 | Epoch: 150, Loss: 0.03890, Train: 1.0000, Val: 0.7750, Best: 0.902, early_stopping: 49\n",
      "index: 4 | Epoch: 200, Loss: 0.05780, Train: 1.0000, Val: 0.8125, Best: 0.902, early_stopping: 99\n",
      "index: 4 | Epoch: 250, Loss: 0.06578, Train: 1.0000, Val: 0.7750, Best: 0.902, early_stopping: 149\n",
      "index: 4 | Epoch: 300, Loss: 0.05073, Train: 1.0000, Val: 0.8000, Best: 0.902, early_stopping: 199\n",
      "index: 5 | Epoch: 050, Loss: 0.07591, Train: 1.0000, Val: 0.8625, Best: 0.8039, early_stopping: 17\n",
      "index: 5 | Epoch: 100, Loss: 0.06315, Train: 1.0000, Val: 0.7625, Best: 0.8824, early_stopping: 25\n",
      "index: 5 | Epoch: 150, Loss: 0.04684, Train: 1.0000, Val: 0.7750, Best: 0.8824, early_stopping: 75\n",
      "index: 5 | Epoch: 200, Loss: 0.08425, Train: 1.0000, Val: 0.7750, Best: 0.8824, early_stopping: 125\n",
      "index: 5 | Epoch: 250, Loss: 0.05350, Train: 1.0000, Val: 0.8375, Best: 0.8824, early_stopping: 175\n",
      "index: 6 | Epoch: 050, Loss: 0.08424, Train: 1.0000, Val: 0.7875, Best: 0.8627, early_stopping: 10\n",
      "index: 6 | Epoch: 100, Loss: 0.04811, Train: 1.0000, Val: 0.8500, Best: 0.8627, early_stopping: 28\n",
      "index: 6 | Epoch: 150, Loss: 0.07711, Train: 1.0000, Val: 0.8250, Best: 0.8824, early_stopping: 16\n",
      "index: 6 | Epoch: 200, Loss: 0.05969, Train: 1.0000, Val: 0.8500, Best: 0.8824, early_stopping: 66\n",
      "index: 6 | Epoch: 250, Loss: 0.07487, Train: 1.0000, Val: 0.7750, Best: 0.8824, early_stopping: 116\n",
      "index: 6 | Epoch: 300, Loss: 0.05168, Train: 1.0000, Val: 0.8125, Best: 0.8824, early_stopping: 166\n",
      "index: 7 | Epoch: 050, Loss: 0.06864, Train: 1.0000, Val: 0.8375, Best: 0.7647, early_stopping: 14\n",
      "index: 7 | Epoch: 100, Loss: 0.04583, Train: 1.0000, Val: 0.8250, Best: 0.8235, early_stopping: 32\n",
      "index: 7 | Epoch: 150, Loss: 0.07575, Train: 1.0000, Val: 0.8250, Best: 0.8235, early_stopping: 82\n",
      "index: 7 | Epoch: 200, Loss: 0.08631, Train: 1.0000, Val: 0.8375, Best: 0.8235, early_stopping: 132\n",
      "index: 7 | Epoch: 250, Loss: 0.06154, Train: 1.0000, Val: 0.8375, Best: 0.8235, early_stopping: 182\n",
      "index: 8 | Epoch: 050, Loss: 0.09788, Train: 1.0000, Val: 0.8000, Best: 0.8627, early_stopping: 7\n",
      "index: 8 | Epoch: 100, Loss: 0.03672, Train: 1.0000, Val: 0.7625, Best: 0.8235, early_stopping: 38\n",
      "index: 8 | Epoch: 150, Loss: 0.09232, Train: 1.0000, Val: 0.7625, Best: 0.8235, early_stopping: 88\n",
      "index: 8 | Epoch: 200, Loss: 0.05762, Train: 1.0000, Val: 0.7625, Best: 0.8235, early_stopping: 138\n",
      "index: 8 | Epoch: 250, Loss: 0.07525, Train: 1.0000, Val: 0.7625, Best: 0.8627, early_stopping: 43\n",
      "index: 8 | Epoch: 300, Loss: 0.07776, Train: 1.0000, Val: 0.8250, Best: 0.8235, early_stopping: 1\n",
      "index: 8 | Epoch: 350, Loss: 0.04272, Train: 1.0000, Val: 0.7750, Best: 0.8235, early_stopping: 51\n",
      "index: 8 | Epoch: 400, Loss: 0.08379, Train: 1.0000, Val: 0.8625, Best: 0.8235, early_stopping: 101\n",
      "index: 8 | Epoch: 450, Loss: 0.03972, Train: 1.0000, Val: 0.8375, Best: 0.8235, early_stopping: 151\n",
      "index: 9 | Epoch: 050, Loss: 0.08377, Train: 1.0000, Val: 0.8625, Best: 0.8824, early_stopping: 0\n",
      "index: 9 | Epoch: 100, Loss: 0.05929, Train: 1.0000, Val: 0.8500, Best: 0.8235, early_stopping: 22\n",
      "index: 9 | Epoch: 150, Loss: 0.06559, Train: 1.0000, Val: 0.8000, Best: 0.8235, early_stopping: 72\n",
      "index: 9 | Epoch: 200, Loss: 0.04536, Train: 1.0000, Val: 0.8125, Best: 0.8235, early_stopping: 122\n",
      "index: 9 | Epoch: 250, Loss: 0.07920, Train: 1.0000, Val: 0.7625, Best: 0.8235, early_stopping: 172\n",
      "test acc: 0.856863 +/- 0.040232\n",
      "[0.7843137254901961, 0.9019607843137255, 0.8431372549019608, 0.9019607843137255, 0.9019607843137255, 0.8823529411764706, 0.8823529411764706, 0.8235294117647058, 0.8235294117647058, 0.8235294117647058]\n"
     ]
    }
   ],
   "source": [
    "in_channels = data.x.shape[-1]\n",
    "out_channels = data.y.max().item() + 1\n",
    "hidden_channels = 128\n",
    "num_layers = 2\n",
    "lr = 2e-2\n",
    "wd = 1e-3\n",
    "dropout_rate = 0.5\n",
    "alpha = 0.5\n",
    "normalize = False\n",
    "jumping_knolwedge = None\n",
    "self_loop = False\n",
    "self_feature_transform = True\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "test_accs = []     \n",
    "\n",
    "for index in range(10):\n",
    "\n",
    "    model = FuzzyDirGCN(\n",
    "        in_channels=data.x.shape[-1], \n",
    "        hidden_channels=hidden_channels, \n",
    "        out_channels=data.y.max().item() + 1, \n",
    "        num_layers=num_layers,\n",
    "        num_nodes=num_nodes,\n",
    "        num_edges=num_edges,\n",
    "        alpha=alpha,\n",
    "        normalize=normalize,\n",
    "        self_feature_transform=self_feature_transform,\n",
    "        self_loop=self_loop,\n",
    "        layerwise_theta=False,\n",
    "        regression=False,\n",
    "        dropout_rate=dropout_rate,\n",
    "        jumping_knowledge=jumping_knolwedge).to(device) \n",
    "    model.reset_parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_test_acc = 0.0\n",
    "    n_non_decreasing_step = 0\n",
    "\n",
    "    for epoch in range(1, 1000):\n",
    "        tr_loss = train(\n",
    "            data.x, data.y, model, optimizer, \n",
    "            edge_index, theta, edge_weight.to(device), \n",
    "            train_mask, index)\n",
    "        train_acc, val_acc, test_acc = test(\n",
    "            data.x, data.y, model, optimizer, \n",
    "            edge_index, theta, edge_weight.to(device), \n",
    "            (train_mask, val_mask, test_mask), index)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            n_non_decreasing_step = 0\n",
    "        else:\n",
    "            n_non_decreasing_step += 1\n",
    "        \n",
    "        if n_non_decreasing_step > 200:\n",
    "            break\n",
    "    \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'index: {index} | '\n",
    "                  f'Epoch: {epoch:03d}, Loss: {tr_loss:.5f}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
    "                  f'Best: {best_test_acc:.4}, early_stopping: {n_non_decreasing_step}')\n",
    "\n",
    "        \n",
    "    \n",
    "    # for n, p in model.named_parameters():\n",
    "    #     print(n, p)\n",
    "    test_accs.append(best_test_acc)\n",
    "    # plt.figure(figsize=(4, 3))\n",
    "    # plt.plot(theta.detach().cpu().numpy(), 'o')\n",
    "    # plt.ylim(0, np.pi/2)\n",
    "    # plt.show()\n",
    "        \n",
    "print(f'test acc: {np.mean(test_accs):.6f} +/- {np.std(test_accs):.6f}')\n",
    "print(test_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f77a6-adde-4a8a-9d3b-10b33afb6f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2-gpu",
   "language": "python",
   "name": "your_environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
